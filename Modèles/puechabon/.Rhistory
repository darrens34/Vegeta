# avoir même moyenne et ecart type entre les 2 jeux de données
# sample
ech <- as.numeric(round(nrow(decathlon)*80/100,0))
Sample <- sample.int(n = nrow(decathlon) , size = ech , replace = F)
train <- decathlon[Sample,]
test  <- decathlon[-Sample,]
res_pca_train <- PCA( train[,1:10], ncp = 10, scale.unit = TRUE, graph=FALSE)
fviz_pca_biplot(res_pca_train)
res_pca_train$eig
fviz_screeplot(res_pca_train, ncp=10)
train_proj <- res_pca_train$ind$coord
# projeter données test
test_standard <- test[,1:10]
res_pca_train$call$centre # moyenne pour train
res_pca_train$call$ecart.type  # e-t pour train
# standardisation par echantillon train (on dit que variables distribuées pareil dans echantillons train et test)
test_standard <- t(apply(test_standard, MARGIN = 1, FUN = function(x) { (x-res_pca_train$call$centre)/res_pca_train$call$ecart.type } ))
# projection (matrix multiplication between individuals and dimensions coordinates)
test_proj <- as.matrix(test_standard) %*% res_pca_train$svd$V
plot(train_proj,pch=19,col="black");points(test_proj,pch=19,col="red")
abline(h=0,col="red",lty="dashed");abline(v=0,col="red",lty="dashed")
###################### Exercice 2 - PCR
# convert to dataframe
train_proj <- as.data.frame(train_proj) # Pour 2 premieres composantes
test_proj <- as.data.frame(test_proj)
# add target column
train_proj$Points <- train$Points
test_proj$Points <- test$Points
# rename variables to work with predict function
colnames(test_proj) <- colnames(train_proj)
# fit
model_pcr <- lm(Points~Dim.1+Dim.2+Dim.3+Dim.4+Dim.5,data = train_proj)
# summary
summary(model_pcr)
# prediction
predict_pcr <- predict.lm(model_pcr,test_proj[,1:5])
rmse <- sqrt(sum((test_proj$Points - predict_pcr)^2)/length(predict_pcr));rmse
plot(x = test_proj$Points, y = predict_pcr,xlab="measured",ylab="fit",pch=19)
abline(a=0,b=1,col="red",lty="dashed")
###################### Exercice 3 - PLSR
library(FactoMineR)
library(factoextra) # pour les graphes
###################### importation des données
# load dataset
data(decathlon)
# view
# decathlon
# résumé
# summary(decathlon)
###################### Exercice 1 split et ACP
# Pourquoi est-il important de décomposer notre base d’apprentissage avant de réaliser l’ACP et la régression ?
# Pour avoir un jeu d'apprentissage et de test
# Quel problème cela va-t-il engendrer pour l’étape de standardisation ?
# avoir même moyenne et ecart type entre les 2 jeux de données
# sample
Sample <- sample.int(n = nrow(decathlon) , size = round(nrow(decathlon)*80/100,0) , replace = F)
Sample <- sample.int(n = nrow(decathlon) , size = round(nrow(decathlon)*80/100,0) , replace = F)
train <- decathlon[Sample,]
test  <- decathlon[-Sample,]
res_pca_train <- PCA( train[,1:10], ncp = 10, scale.unit = TRUE, graph=FALSE)
fviz_pca_biplot(res_pca_train)
res_pca_train$eig
fviz_screeplot(res_pca_train, ncp=10)
train_proj <- res_pca_train$ind$coord
# projeter données test
test_standard <- test[,1:10]
res_pca_train$call$centre # moyenne pour train
res_pca_train$call$ecart.type  # e-t pour train
# standardisation par echantillon train (on dit que variables distribuées pareil dans echantillons train et test)
test_standard <- t(apply(test_standard, MARGIN = 1, FUN = function(x) { (x-res_pca_train$call$centre)/res_pca_train$call$ecart.type } ))
# projection (matrix multiplication between individuals and dimensions coordinates)
test_proj <- as.matrix(test_standard) %*% res_pca_train$svd$V
plot(train_proj,pch=19,col="black");points(test_proj,pch=19,col="red")
abline(h=0,col="red",lty="dashed");abline(v=0,col="red",lty="dashed")
###################### Exercice 2 - PCR
# convert to dataframe
train_proj <- as.data.frame(train_proj) # Pour 2 premieres composantes
test_proj <- as.data.frame(test_proj)
# add target column
train_proj$Points <- train$Points
test_proj$Points <- test$Points
# rename variables to work with predict function
colnames(test_proj) <- colnames(train_proj)
# fit
model_pcr <- lm(Points~Dim.1+Dim.2+Dim.3+Dim.4,data = train_proj)
# summary
summary(model_pcr)
# prediction
predict_pcr <- predict.lm(model_pcr,test_proj[,1:4])
rmse <- sqrt(sum((test_proj$Points - predict_pcr)^2)/length(predict_pcr));rmse
plot(x = test_proj$Points, y = predict_pcr,xlab="measured",ylab="fit",pch=19)
abline(a=0,b=1,col="red",lty="dashed")
Sample <- sample.int(n = nrow(decathlon) , size = round(nrow(decathlon)*80/100,0) , replace = F)
Sample <- sample.int(n = nrow(decathlon) , size = round(nrow(decathlon)*80/100,0) , replace = F)
train <- decathlon[Sample,]
test  <- decathlon[-Sample,]
res_pca_train <- PCA( train[,1:10], ncp = 10, scale.unit = TRUE, graph=FALSE)
fviz_pca_biplot(res_pca_train)
res_pca_train$eig
fviz_screeplot(res_pca_train, ncp=10)
train_proj <- res_pca_train$ind$coord
# projeter données test
test_standard <- test[,1:10]
res_pca_train$call$centre # moyenne pour train
res_pca_train$call$ecart.type  # e-t pour train
# standardisation par echantillon train (on dit que variables distribuées pareil dans echantillons train et test)
test_standard <- t(apply(test_standard, MARGIN = 1, FUN = function(x) { (x-res_pca_train$call$centre)/res_pca_train$call$ecart.type } ))
# projection (matrix multiplication between individuals and dimensions coordinates)
test_proj <- as.matrix(test_standard) %*% res_pca_train$svd$V
plot(train_proj,pch=19,col="black");points(test_proj,pch=19,col="red")
abline(h=0,col="red",lty="dashed");abline(v=0,col="red",lty="dashed")
###################### Exercice 2 - PCR
# convert to dataframe
train_proj <- as.data.frame(train_proj) # Pour 2 premieres composantes
test_proj <- as.data.frame(test_proj)
# add target column
train_proj$Points <- train$Points
test_proj$Points <- test$Points
# rename variables to work with predict function
colnames(test_proj) <- colnames(train_proj)
# fit
model_pcr <- lm(Points~Dim.1+Dim.2+Dim.3+Dim.4,data = train_proj)
# summary
summary(model_pcr)
# prediction
predict_pcr <- predict.lm(model_pcr,test_proj[,1:4])
rmse <- sqrt(sum((test_proj$Points - predict_pcr)^2)/length(predict_pcr));rmse
plot(x = test_proj$Points, y = predict_pcr,xlab="measured",ylab="fit",pch=19)
abline(a=0,b=1,col="red",lty="dashed")
library(pls)
plsr_fit <- plsr(Points ~ ., data = train[,c(1:10,12)], scale = TRUE )
plsr_fit <- plsr(Points ~  `100m`+ Long.jump +Shot.put +High.jump  +`400m`+ `110m.hurdle`+ Discus +Pole.vault +Javeline + `1500m`, data = train, scale = TRUE )
summary(plsr_fit)
# evolution RMSEP
plot(RMSEP(plsr_fit), legendpos = "topright") # 6 composantes
# Precision de la prédiction
plot(plsr_fit, ncomp = 1, asp = 1, line = TRUE)
plot(plsr_fit, ncomp = 2, asp = 1, line = TRUE) # 2 c'est bien
plot(plsr_fit, ncomp = 3, asp = 1, line = TRUE)
abline(a=0,b=1,col="red",lty="dashed")
# Selectionner le nombre de composantes
plsr_fit <- plsr(Points ~ ., data = train[,c(1:10,12)], scale = TRUE ,validation = "CV")
selectNcomp(plsr_fit,method = c("onesigma"), ncomp = plsr_fit$ncomp,plot=TRUE)
plsr_fit <- plsr(Points ~ ., data = train[,c(1:10,12)], scale = TRUE ,ncomp = 6 )
pred <- predict(plsr_fit, train[,c(1:10)])
pred # récupérer le dernier seulement
plsr_fit
pred
tail(pred)
as.numeric(pred)
pre[]
pred[]
pred[[6]]
pred[1]
?plsr
predict(plsr_fit, ncomp = 6, newdata = test) %>% as.data.frame %>% pull()
library(tidyverse)
library(dplyr)
library(tidyr)
predict(plsr_fit, ncomp = 6, newdata = test) %>% as.data.frame %>% pull()
predict(plsr_fit, ncomp = 6, newdata = test)
pred <- predict(plsr_fit, train[,c(1:10)],ncomp = 6 )
pred
train
test
pred <- predict(plsr_fit, test[,c(1:10)],ncomp = 6 )
pred
rmse <- sqrt(mean((train$Points-pred)^2))
rmse <- sqrt(mean((test$Points-pred)^2))
rmse
rmse <- round(sqrt(mean((test$Points-pred)^2)),2)
rmse
pcr_fit <- pcr(Points ~ ., data = train[,c(1:10,12)], scale = TRUE ,ncomp = 6)
pcr_fit
pred <- predict(pcr_fit, ncomp = 6, newdata =  test[,c(1:10)])
pred
rmse <- round(sqrt(mean((test$Points-pred)^2)),2)
rmse
?pcr
pcr_fit <- pcr(Points ~ ., data = train[,c(1:10,12)], scale = TRUE,validation = "CV" )
selectNcomp(pcr_fit,method = c("onesigma"), ncomp = pcr_fit$ncomp,plot=TRUE)
pcr_fit <- pcr(Points ~ ., data = train[,c(1:10,12)], scale = TRUE,ncomp=10)
pred <- predict(pcr_fit, ncomp = 6, newdata =  test[,c(1:10)])
rmse <- round(sqrt(mean((test$Points-pred)^2)),2)
rmse
pred <- predict(pcr_fit, ncomp = 6, newdata =  test[,c(1:10)])
rmse <- round(sqrt(mean((test$Points-pred)^2)),2)
rmse
pred <- predict(pcr_fit, ncomp = 10, newdata =  test[,c(1:10)])
rmse <- round(sqrt(mean((test$Points-pred)^2)),2)
rmse
pcr_fit <- pcr(Points ~ ., data = train[,c(1:10,12)], scale = TRUE,ncomp=6)
pred <- predict(pcr_fit, ncomp = 6, newdata =  test[,c(1:10)])
rmse <- round(sqrt(mean((test$Points-pred)^2)),2)
rmse
pcr_fit <- pcr(Points ~ ., data = train[,c(1:10,12)], scale = TRUE,validation = "CV" )
selectNcomp(pcr_fit,method = c("onesigma"), ncomp = pcr_fit$ncomp,plot=TRUE)
pcr_fit <- pcr(Points ~ ., data = train[,c(1:10,12)], scale = TRUE,ncomp=6)
lm_fit <- lm(Points ~ ., data = train[,c(1:10,12)])
summary(lm_fit)
?selectNcomp
plot(RMSEP(plsr_fit), legendpos = "topright") # 6 composantes
summary(plsr_fit)
plot(RMSEP(plsr_fit), legendpos = "topright") # 6 composantes
plot(plsr_fit, ncomp = 1, asp = 1, line = TRUE)
plot(plsr_fit, ncomp = 2, asp = 1, line = TRUE) # 2 c'est bien
plot(plsr_fit, ncomp = 3, asp = 1, line = TRUE)
abline(a=0,b=1,col="red",lty="dashed")
plsr_fit <- plsr(Points ~ ., data = train[,c(1:10,12)], scale = TRUE ,validation = "CV")
selectNcomp(plsr_fit,method = c("onesigma"), ncomp = plsr_fit$ncomp,plot=TRUE) # 6
plsr_fit <- plsr(Points ~ ., data = train[,c(1:10,12)], scale = TRUE ,ncomp = 6 )
pred <- predict(plsr_fit, test[,c(1:10)],ncomp = 6 )
rmse <- round(sqrt(mean((test$Points-pred)^2)),2)
rmse
pcr_fit <- pcr(Points ~ ., data = train[,c(1:10,12)], scale = TRUE,validation = "CV" )
selectNcomp(pcr_fit,method = c("onesigma"), ncomp = pcr_fit$ncomp,plot=TRUE) # 10
pcr_fit <- pcr(Points ~ ., data = train[,c(1:10,12)], scale = TRUE,ncomp=6)
pred <- predict(pcr_fit, ncomp = 6, newdata =  test[,c(1:10)])
rmse <- round(sqrt(mean((test$Points-pred)^2)),2)
rmse
selectNcomp(pcr_fit,method = c("onesigma"), ncomp = pcr_fit$ncomp,plot=TRUE) # 10
pcr_fit <- pcr(Points ~ ., data = train[,c(1:10,12)], scale = TRUE,ncomp=10)
pred <- predict(pcr_fit, ncomp = 10, newdata =  test[,c(1:10)])
rmse <- round(sqrt(mean((test$Points-pred)^2)),2)
rmse
pcr_fit <- pcr(Points ~ ., data = train[,c(1:10,12)], scale = TRUE,ncomp=6)
pred <- predict(pcr_fit, ncomp = 6, newdata =  test[,c(1:10)])
rmse <- round(sqrt(mean((test$Points-pred)^2)),2)
rmse
lm_fit <- lm(Points ~ ., data = train[,c(1:6)])
data
train[,c(1:6)]
head(train)
lm_fit <- lm(Points ~ ., data = train[,c(1:6,12)])
summary(lm_fit)
lm_fit <- lm(Points ~ ., data = train[,c(1:10,12)])
summary(lm_fit)
lm_fit <- lm(Points ~ ., data = train[,c(2,4,7,8,9,10,12)])
summary(lm_fit)
pred <- predict(lm_fit,  newdata =  test[,c(2,4,7,8,9,10)])
rmse <- round(sqrt(mean((test$Points-pred)^2)),2)
rmse #  29.26
?AIC
AIC(plsr_fit)
?AICpls
?pls
??pls
install.packages("plsRglm")
library(plsRglm)
plsr_fit <- plsr(Points ~ ., data = train[,c(1:10,12)], scale = TRUE ,ncomp = 6 )
pred_plsr_fit <- predict(plsr_fit, test[,c(1:10)],ncomp = 6 )
# RMSE
rmse <- round(sqrt(mean((test$Points-pred_plsr_fit)^2)),2)
rmse #  4.85
pred_plsr_fit
AICpls(test$Points-pred_plsr_fit,ncomp=6)
pred_pcr_fit <- predict(pcr_fit, ncomp = 6, newdata =  test[,c(1:10)])
rmse <- round(sqrt(mean((test$Points-pred_pcr_fit)^2)),2)
rmse #  29.26
AICpls(test$Points-pred_pcr_fit,ncomp=6)
AIC(lm_fit)
pred_lm <- predict(lm_fit,  newdata =  test[,c(2,4,7,8,9,10)])
rmse <- round(sqrt(mean((test$Points-pred_lm)^2)),2)
rmse #  88.06
AICpls(test$Points-pred_lm,ncomp=6)
plot(RMSEP(plsr_fit), legendpos = "topright") # 6 composantes
library(mda802)
library(MASS)
data("clash_dataset")
library(mda802)
library(MASS)
data("clash_dataset")
load("F:/MIASHS/UEs/ACP/clash_dataset.RData")
data("clash_dataset")
head(clash_dataset)
names(clash_dataset)
clash_dataset = clash_dataset[,-c(10,11)]
df <- clash_dataset[,c(6:15)]
?lda
lda_fit <- MASS::lda(df)
df
lda(df)
summary(df)
lda(df)
as.matrix(df)
lda_fit <- MASS::lda(Rarity~.,data = df)
lda_fit
plda <- predict(object = lda_fit, newdata = df)
plda
lda_fit$svd
lda_fit
lda_fit$svd^2
library(mda802)
data(mushrooms)
devtools::install_github("UMC800/UMC802-MDA")
data(mushrooms)
library(mda802)
if (!require("mda802", character.only = TRUE)) {
devtools::install_github("UMC800/UMC802-MDA")
}
library(devtools)
if (!require("mda802", character.only = TRUE)) {
devtools::install_github("UMC800/UMC802-MDA")
}
library(mda802)
data(mushrooms)
library(mda802)
data(mushrooms)
head(mushrooms)
mushrooms
dim(mushrooms)
head(mushrooms)
mushrooms_ctg <- table(mushrooms$cap-color,mushrooms$habitat)
mushrooms_ctg <- table(mushrooms$`cap-color`,mushrooms$habitat)
mushrooms_ctg
mushrooms_freq <- prop.table(mushrooms$`cap-color`,mushrooms$habitat)
mushrooms_freq <- prop.table(mushrooms_ctg)
mushrooms_freq
?table
?prop.table
mushrooms_freq_r <- prop.table(mushrooms_ctg,margin = 1)
mushrooms_freq_r
mushrooms_freq_c <- prop.table(mushrooms_ctg,margin = 2)
mushrooms_freq_c
mushrooms_freq_c["brown","leaves"]
mushrooms_freq_c["brown","leaves"] * 100
mushrooms_ctg
mushrooms_ctg["pink","grasses"]
mushrooms_freq
mushrooms_freq["pink","grasses"] * 100
mushrooms_freq_c["brown","leaves"] * 100
mushrooms_freq_r
(mushrooms_freq_r["brown","woods"]+mushrooms_freq_r["brown","paths"]) * 100 # 60.58
6*9
chisq.test(mushrooms$`cap-color`,mushrooms$habitat)
?chisq.tes
?chisq.test
chisq.test(mushrooms_ctg)
chisq.test(mushrooms_ctg)
library(FactoMineR)
?CA
afc <- CA(mushrooms_ctg,ncp=5)
afc
afc$eig
afc$col
# load dataset
data(decathlon)
# view
decathlon
# résumé
summary(decathlon)
###################### L'ACP
# On standardise les variables pour les simplifier et les ramener à la même échelle.
res_pca <- PCA(decathlon[,1:10], ncp = 5, scale.unit = TRUE, graph=FALSE)
res_pca
barplot(res_pca$eig[,2])
# inertie
res_pca$ind$coord[1,]^2/sum(res_pca$ind$coord[1,]^2)
res_pca$ind$coord$cos2[1,]
res_pca$ind$cos2[1,]
res_pca$ind$coord
res_pca$ind$coord[1,]^2/sum(res_pca$ind$coord^2)
res_pca$ind$coord$cos2[1,]
res_pca$ind$cos2[1,]
res_pca$ind$coord[1,]^2/sum(res_pca$ind$coord[1,]^2)
res_pca$ind$coord[1,]
res_pca$ind$coord
sum(res_pca$ind$coord[1,]^2)
sum(res_pca$ind$coord^2)
sum(res_pca$ind$coord[,1]^2)
res_pca$ind$coord[1,]
res_pca$ind$cos2[1,]
res_pca$ind$coord[1,]^2/sum(res_pca$ind$coord[,1]^2)
res_pca$ind$coord[1,]^2/sum(res_pca$ind$coord[1,]^2)
sum(res_pca$ind$coord[,1]^2)
sum(res_pca$ind$coord[,1]^2)
sum(res_pca$ind$coord[,2]^2)
res_pca$ind$coord[1,]^2
0.6266744/ 134.1481
data(mushrooms)
head(mushrooms)
dim(mushrooms)
###### Exercice 1 cap-color & habitat #########################
# contingency
mushrooms_ctg <- table(mushrooms$`cap-color`,mushrooms$habitat)
# freq.
# contingency / nombre totale
mushrooms_freq <- prop.table(mushrooms_ctg)
# margins
# profil ligne
# divisé par le nb d'indiv de la ligne
mushrooms_freq_r <- prop.table(mushrooms_ctg,margin = 1)
# profil colonne
# divisé par le nb indiv de la colonne
mushrooms_freq_c <- prop.table(mushrooms_ctg,margin = 2)
# Par rapport aux champignons retrouvés sur les feuilles, quelle est la proportion de ceux qui sont marrons ?
# profil colonne :
mushrooms_freq_c["brown","leaves"] * 100 # 60.58
# Par rapport à l’échantillon total, quelle est la proportion des champignons aux chapeaux de couleur rose et que l’on retrouve en prairie
# Table de contingence
mushrooms_freq["pink","grasses"] * 100 # 0.15
# Par rapport aux champignons de couleur marron, quelle est la proportion de ceux que l’on retrouve dans les bois ou sur les chemins ?
# Profil ligne
(mushrooms_freq_r["brown","woods"]+mushrooms_freq_r["brown","paths"]) * 100 # 54.82
###### Exercice 2 Mesure de l'indépendance #########################
# la valeur du test du doit être supérieure à quelle valeur (approximativement) pour pouvoir rejeter l’hypothèses d’indépendance au degrès de confiance de 5%.
# H0 : C'est indépendant
# Khi 2 calc : Somme((Fqce obs - Fqce Theo)^2 / Fqce The)
# Si variable INDEPENDANTE alors ça suit une loi du Khi de (i-1)(j-1)
# ddl=(Nb lignes -1) x (Nb colonnes -1), soit ici (7-1)(10-1)
6*9 # 54
# Qd c'est indépendant, la proba d'etre au dessus de Khi2 Theo est tres faible (5% ici)
# Si on est au dessus, on peut dire que c dépendant avec un risque de 5% de se tromper quand même
#  Khi2 Calculé < Khi2 théorique  alors on garde H0
#  Khi2 Calculé >Khi2 théorique  alors on rejette H0 :  les variables sont dépendantes
# Alpha = 0.05
# Khi2 theorique = 67.50
# Alpha = 5% de rejetter H0 a tord
chisq.test(mushrooms$`cap-color`,mushrooms$habitat)
chisq.test(mushrooms_ctg)
# Khi2 calc = 5205.1 > Khi2 theorique  : On rejette H0
###### Exercice 3 #########################
afc <- CA(mushrooms_ctg,ncp=5)
afc
# On retrouves les valeurs propres, coordonnées, contributions, cos2
afc$eig
library(factoextra)
fviz_screeplot(afc, ncp=10)
fviz_pca_var(afc, axes=c(1,2), repel = TRUE)
fviz_contrib(afc, choice = "col", axes = 1)
fviz_pca_biplot(afc, repel = TRUE)
fviz_contrib(afc, choice = "var", axes = 1)
fviz_contrib(afc, choice = "row", axes = 1)
fviz_screeplot(afc, ncp=5)
afc
afc <- CA(mushrooms_ctg,ncp=5)
fviz_contrib(afc, choice = "col", axes = 2)
fviz_contrib(afc, choice = "row", axes = 2)
afc$col$cos2
afc$var$cos2
afc$row$cos2
fviz_contrib(afc, choice = "col", axes = 2)
fviz_screeplot(afc, ncp=5)
########## IMPORTATION #################
path<-"F:/MIASHS/TER/Vegeta/data/data_pour_visu_nabil/Puechabon/correlations/Puechabon_2010_post_model.csv"
data <- read.table(path,sep="\t",dec=".",header=T,na.strings = c("-9999","NA"))
head(data)
setwd("F:/MIASHS/TER/Vegeta/Anaelle/R/puechabon")
summary(data)
########## Librairies ################
library(ggplot2)
theme_set(theme_bw())
head(data)
p<-ggplot(data,
aes(x=SLE_3h, y=SAP_FLOW))+
theme(axis.text=element_text(size=12,color="black"),
axis.title=element_text(size=14))+
geom_point( size = 2, color = "black") +
xlab(bquote('Latent heat storage flux (W '*m^-2*') 3 heures avant'))+
ylab(bquote('Flux de sève (mmol '*H[2]*'O '*~ m^-2~s^-1*')'))
p+ annotate(geom="text", x=-40, y=10, label="R² = 0.25",color="black")
#geom_smooth(method='lm',formula=y~x,color="red")
summary(lm(data$SAP_FLOW~data$SLE_3h))
p<-ggplot(data,
aes(x=SLE_3h, y=SAP_FLOW))+
theme(axis.text=element_text(size=12,color="black"),
axis.title=element_text(size=14))+
geom_point( size = 2, color = "black") +
xlab(bquote('Latent heat storage flux (W '*m^-2*') 3 heures avant'))+
ylab(bquote('Flux de sève (mmol '*H[2]*'O '*~ m^-2~s^-1*')'))
p+ annotate(geom="text", x=-40, y=10, label="R² = 0.02",color="black")
#geom_smooth(method='lm',formula=y~x,color="red")
summary(lm(data$SAP_FLOW~data$SLE_3h))
p+ annotate(geom="text", x=-100, y=10, label="R² = 0.02",color="black")
head(data)
summary(lm(data$SAP_FLOW~data$ZL_3h))
p<-ggplot(data,
aes(x=ZL_3h, y=SAP_FLOW))+
theme(axis.text=element_text(size=12,color="black"),
axis.title=element_text(size=14))+
geom_point( size = 2, color = "black") +
xlab(bquote('Parametre de stabilité'))+
ylab(bquote('Flux de sève (mmol '*H[2]*'O '*~ m^-2~s^-1*')'))
p+ annotate(geom="text", x=-100, y=10, label="R² = 0.09",color="black")
#geom_smooth(method='lm',formula=y~x,color="red")
summary(lm(data$SAP_FLOW~data$ZL_3h))
p+ annotate(geom="text", x=-40, y=10, label="R² = 0.09",color="black")
summary(lm(data$SAP_FLOW~data$ZL_3h))
#  ZL_3h
p<-ggplot(data,
aes(x=ZL_3h, y=SAP_FLOW))+
theme(axis.text=element_text(size=12,color="black"),
axis.title=element_text(size=14))+
geom_point( size = 2, color = "black") +
xlab(bquote('Parametre de stabilité'))+
ylab(bquote('Flux de sève (mmol '*H[2]*'O '*~ m^-2~s^-1*')'))
p+ annotate(geom="text", x=-40, y=10, label="R² = 0.09",color="black")
#geom_smooth(method='lm',formula=y~x,color="red")
summary(lm(data$SAP_FLOW~data$ZL_3h))
head(data)
p<-ggplot(data,
aes(x= VPD, y=SAP_FLOW))+
theme(axis.text=element_text(size=12,color="black"),
axis.title=element_text(size=14))+
geom_point( size = 2, color = "black") +
xlab(bquote('Déficit de pression de vapeur'))+
ylab(bquote('Flux de sève (mmol '*H[2]*'O '*~ m^-2~s^-1*')'))
p+ annotate(geom="text", x=-40, y=10, label="R² = 0.09",color="black")
#geom_smooth(method='lm',formula=y~x,color="red")
summary(lm(data$SAP_FLOW~data$ VPD))
p+ annotate(geom="text", x=1, y=10, label="R² = 0.66",color="black")
p+ annotate(geom="text", x=0.5, y=10, label="R² = 0.66",color="black")
